{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKBywENSaK4KWXtvAsoq/Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tanu-N-Prabhu/Python/blob/master/Machine%20Learning%20Interview%20Prep%20Questions/Unsupervised%20Learning%20Algorithms/Dimensionality%20Reduction/Autoencoders/autoencoder_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Autoencoders from Scratch (No Deep Learning Libraries)\n",
        "\n",
        "This notebook demonstrates a **basic autoencoder** implemented from scratch using only **NumPy**. Autoencoders are powerful neural networks used for **unsupervised learning**, especially in **dimensionality reduction**, **feature learning**, and **anomaly detection**.\n",
        "\n",
        "\n",
        "## What is an Autoencoder?\n",
        "\n",
        "An **autoencoder** is a special kind of feedforward neural network trained to copy its input to its output.\n",
        "\n",
        "It consists of two parts:\n",
        "- **Encoder**: Compresses the input into a smaller (latent) representation.\n",
        "- **Decoder**: Reconstructs the input from the compressed version.\n",
        "\n",
        "Autoencoders learn meaningful representations by minimizing the reconstruction error.\n",
        "\n",
        "## Structure\n",
        "\n",
        "```\n",
        "Input → Encoder → Bottleneck (latent) → Decoder → Output\n",
        "```\n",
        "\n",
        "## Generate Sample Data"
      ],
      "metadata": {
        "id": "GisLTc-rjprr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Load and scale the data\n",
        "digits = load_digits()\n",
        "X = digits.data\n",
        "X = MinMaxScaler().fit_transform(X)\n",
        "print(X)\n",
        "print(\"Data shape:\", X.shape)  # (1797, 64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ixxv5wnj6xb",
        "outputId": "e52cc68e-c7aa-4487-8a59-b6be370f500b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.     0.     0.3125 ... 0.     0.     0.    ]\n",
            " [0.     0.     0.     ... 0.625  0.     0.    ]\n",
            " [0.     0.     0.     ... 1.     0.5625 0.    ]\n",
            " ...\n",
            " [0.     0.     0.0625 ... 0.375  0.     0.    ]\n",
            " [0.     0.     0.125  ... 0.75   0.     0.    ]\n",
            " [0.     0.     0.625  ... 0.75   0.0625 0.    ]]\n",
            "Data shape: (1797, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Autoencoder Model with NumPy\n",
        "\n",
        "```\n",
        "1 hidden layer encoder → bottleneck → 1 hidden layer decoder\n",
        "```"
      ],
      "metadata": {
        "id": "1pIedtmckBgs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Architecture\n",
        "n_input = X.shape[1]      # 64\n",
        "n_hidden = 32             # Encoder layer\n",
        "n_code = 16               # Bottleneck\n",
        "n_hidden2 = 32            # Decoder layer\n",
        "n_output = n_input        # Reconstruct input\n",
        "\n",
        "# Initialize weights and biases\n",
        "def init_weights(shape):\n",
        "    return np.random.randn(*shape) * 0.1\n",
        "\n",
        "W1 = init_weights((n_input, n_hidden))\n",
        "b1 = np.zeros(n_hidden)\n",
        "\n",
        "W2 = init_weights((n_hidden, n_code))\n",
        "b2 = np.zeros(n_code)\n",
        "\n",
        "W3 = init_weights((n_code, n_hidden2))\n",
        "b3 = np.zeros(n_hidden2)\n",
        "\n",
        "W4 = init_weights((n_hidden2, n_output))\n",
        "b4 = np.zeros(n_output)\n",
        "\n",
        "# Activation functions\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    s = sigmoid(x)\n",
        "    return s * (1 - s)"
      ],
      "metadata": {
        "id": "Xl_7Tst5kIJ9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the Autoencoder"
      ],
      "metadata": {
        "id": "nn_fQlHwkV7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training settings\n",
        "epochs = 100\n",
        "lr = 0.1\n",
        "\n",
        "losses = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    for x in X:\n",
        "        ## FORWARD PASS\n",
        "        x = x.reshape(1, -1)\n",
        "\n",
        "        z1 = x @ W1 + b1\n",
        "        a1 = sigmoid(z1)\n",
        "\n",
        "        z2 = a1 @ W2 + b2\n",
        "        code = sigmoid(z2)  # Bottleneck\n",
        "\n",
        "        z3 = code @ W3 + b3\n",
        "        a3 = sigmoid(z3)\n",
        "\n",
        "        z4 = a3 @ W4 + b4\n",
        "        output = sigmoid(z4)\n",
        "\n",
        "        ## LOSS (Mean Squared Error)\n",
        "        error = output - x\n",
        "        loss = np.mean(error ** 2)\n",
        "        total_loss += loss\n",
        "\n",
        "        ## BACKPROP\n",
        "        d4 = error * sigmoid_derivative(z4)\n",
        "        d3 = d4 @ W4.T * sigmoid_derivative(z3)\n",
        "        d2 = d3 @ W3.T * sigmoid_derivative(z2)\n",
        "        d1 = d2 @ W2.T * sigmoid_derivative(z1)\n",
        "\n",
        "        # Update weights and biases\n",
        "        W4 -= lr * a3.T @ d4\n",
        "        b4 -= lr * d4.flatten()\n",
        "\n",
        "        W3 -= lr * code.T @ d3\n",
        "        b3 -= lr * d3.flatten()\n",
        "\n",
        "        W2 -= lr * a1.T @ d2\n",
        "        b2 -= lr * d2.flatten()\n",
        "\n",
        "        W1 -= lr * x.T @ d1\n",
        "        b1 -= lr * d1.flatten()\n",
        "\n",
        "    losses.append(total_loss / len(X))\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {total_loss / len(X):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LT9_wUF1kWkZ",
        "outputId": "0b91950e-73d0-4692-fa73-60f55bb61537"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.0756\n",
            "Epoch 10, Loss: 0.0495\n",
            "Epoch 20, Loss: 0.0287\n",
            "Epoch 30, Loss: 0.0221\n",
            "Epoch 40, Loss: 0.0170\n",
            "Epoch 50, Loss: 0.0142\n",
            "Epoch 60, Loss: 0.0120\n",
            "Epoch 70, Loss: 0.0111\n",
            "Epoch 80, Loss: 0.0102\n",
            "Epoch 90, Loss: 0.0094\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize the Reconstructions\n"
      ],
      "metadata": {
        "id": "LAVnTNWpkbsB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot original vs reconstructed digits\n",
        "n = 10\n",
        "plt.figure(figsize=(10, 3))\n",
        "for i in range(n):\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(X[i].reshape(8, 8), cmap=\"gray\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    # Forward pass\n",
        "    x = X[i].reshape(1, -1)\n",
        "    a1 = sigmoid(x @ W1 + b1)\n",
        "    code = sigmoid(a1 @ W2 + b2)\n",
        "    a3 = sigmoid(code @ W3 + b3)\n",
        "    output = sigmoid(a3 @ W4 + b4)\n",
        "\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(output.reshape(8, 8), cmap=\"gray\")\n",
        "    plt.axis(\"off\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "JR_ry1GCkkmX",
        "outputId": "cad71dc7-1f29-485a-b5d8-946e7de2bfb5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x300 with 20 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary\n",
        "\n",
        "- Autoencoders learn compressed representations of data\n",
        "- They reconstruct input with minimal loss\n",
        "- We implemented:\n",
        "  - Forward propagation (encoder → decoder)\n",
        "  - Loss function: MSE\n",
        "  - Backpropagation using NumPy\n",
        "- Visualized digit reconstruction from raw input\n"
      ],
      "metadata": {
        "id": "dPRCWKoVknvG"
      }
    }
  ]
}