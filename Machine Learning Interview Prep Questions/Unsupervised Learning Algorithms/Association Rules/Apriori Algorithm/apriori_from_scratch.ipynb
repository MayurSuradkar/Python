{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOo/QawXNeu7NBPammlQgnr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tanu-N-Prabhu/Python/blob/master/Machine%20Learning%20Interview%20Prep%20Questions/Unsupervised%20Learning%20Algorithms/Association%20Rules/Apriori%20Algorithm/apriori_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Apriori Algorithm from Scratch\n",
        "\n",
        "This notebook implements the **Apriori algorithm** from scratch using pure Python. It’s a classic algorithm used in **association rule mining**, commonly applied in **market basket analysis**, **recommendation systems**, and **retail analytics**.\n",
        "\n",
        "We'll identify frequent itemsets and generate association rules like:\n",
        "> If a customer buys bread and butter, they are likely to buy jam.\n",
        "\n",
        "## Sample Dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "SSVz1rHdsNb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample transactions (each transaction is a list of items)\n",
        "transactions = [\n",
        "    ['milk', 'bread', 'butter'],\n",
        "    ['bread', 'butter'],\n",
        "    ['milk', 'bread'],\n",
        "    ['milk', 'bread', 'butter', 'jam'],\n",
        "    ['bread', 'jam'],\n",
        "    ['milk', 'bread', 'jam'],\n",
        "]\n",
        "\n",
        "transactions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6q8PDQZsVh7",
        "outputId": "6a4fa9c7-4c7e-452a-fee6-657185d7f5e5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['milk', 'bread', 'butter'],\n",
              " ['bread', 'butter'],\n",
              " ['milk', 'bread'],\n",
              " ['milk', 'bread', 'butter', 'jam'],\n",
              " ['bread', 'jam'],\n",
              " ['milk', 'bread', 'jam']]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Apriori Core Functions\n",
        "\n",
        "### Helper: Get Unique Items"
      ],
      "metadata": {
        "id": "I_12JH0xsbwy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_unique_items(transactions):\n",
        "    items = set()\n",
        "    for tx in transactions:\n",
        "        items.update(tx)\n",
        "    return sorted(list(items))"
      ],
      "metadata": {
        "id": "TjZZtf3vsdvo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate Candidate Itemsets"
      ],
      "metadata": {
        "id": "Kg4nYfJ3sgvO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import combinations\n",
        "\n",
        "def generate_candidates(prev_frequent, k):\n",
        "    candidates = set()\n",
        "    prev_items = list(prev_frequent)\n",
        "    for i in range(len(prev_items)):\n",
        "        for j in range(i + 1, len(prev_items)):\n",
        "            combo = sorted(set(prev_items[i]) | set(prev_items[j]))\n",
        "            if len(combo) == k:\n",
        "                candidates.add(tuple(combo))\n",
        "    return candidates"
      ],
      "metadata": {
        "id": "nEF33gy3siUY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate Support for Itemsets\n"
      ],
      "metadata": {
        "id": "fYCq_8Cnsj4y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_support(candidates, transactions):\n",
        "    support_count = {}\n",
        "    for candidate in candidates:\n",
        "        count = sum(1 for tx in transactions if set(candidate).issubset(set(tx)))\n",
        "        support_count[candidate] = count\n",
        "    return support_count"
      ],
      "metadata": {
        "id": "Kb84kYPmsmxE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filter Frequent Itemsets\n",
        "\n"
      ],
      "metadata": {
        "id": "nCzilIU5sowZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_frequent(support_count, min_support):\n",
        "    n = len(transactions)\n",
        "    return {itemset: count / n for itemset, count in support_count.items() if count / n >= min_support}"
      ],
      "metadata": {
        "id": "U2OYCZtKsrr2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Apriori Algorithm"
      ],
      "metadata": {
        "id": "q9tjJ0GWstrC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def apriori(transactions, min_support=0.4):\n",
        "    items = get_unique_items(transactions)\n",
        "    frequent_itemsets = {}\n",
        "    k = 1\n",
        "\n",
        "    # Initial 1-itemsets\n",
        "    candidates = [(item,) for item in items]\n",
        "    support_count = calculate_support(candidates, transactions)\n",
        "    Lk = filter_frequent(support_count, min_support)\n",
        "    frequent_itemsets.update(Lk)\n",
        "\n",
        "    while Lk:\n",
        "        k += 1\n",
        "        candidates = generate_candidates(Lk.keys(), k)\n",
        "        support_count = calculate_support(candidates, transactions)\n",
        "        Lk = filter_frequent(support_count, min_support)\n",
        "        frequent_itemsets.update(Lk)\n",
        "\n",
        "    return frequent_itemsets"
      ],
      "metadata": {
        "id": "uHrtVX5ysv46"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example Usage"
      ],
      "metadata": {
        "id": "V6npB2Ycsye_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frequent_itemsets = apriori(transactions, min_support=0.4)\n",
        "\n",
        "print(\"Frequent Itemsets (Support ≥ 0.4):\")\n",
        "for itemset, support in frequent_itemsets.items():\n",
        "    print(f\"{itemset}: {support:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVluUHoes1uo",
        "outputId": "4bc0a7bc-86b3-4154-afc5-3da8bad5687f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frequent Itemsets (Support ≥ 0.4):\n",
            "('bread',): 1.00\n",
            "('butter',): 0.50\n",
            "('jam',): 0.50\n",
            "('milk',): 0.67\n",
            "('bread', 'jam'): 0.50\n",
            "('bread', 'milk'): 0.67\n",
            "('bread', 'butter'): 0.50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Association rules\n",
        "\n",
        "Perfect! Let’s extend the notebook to generate association rules with:\n",
        "\n",
        "\n",
        "*   **Confidence**: Measures how often rule holds true\n",
        "\n",
        "*   **Lift**: Measures how much more likely consequent is, given the antecedent\n",
        "\n",
        "\n",
        "### Association Rules from Frequent Itemsets\n",
        "We’ll generate rules like:\n",
        "\n",
        "```\n",
        "milk → bread   (support=0.67, confidence=1.00, lift=1.50)\n",
        "```\n",
        "\n",
        "### Definitions\n",
        "* Support `(A → B) = P(A ∪ B)`\n",
        "* Confidence `(A → B) = P(A ∪ B) / P(A)`\n",
        "* Lift `(A → B) = Confidence(A → B) / P(B)`\n",
        "\n",
        "### Add Rule Generator\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8I8F8kPptpHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_association_rules(frequent_itemsets, min_confidence=0.6, min_lift=1.0):\n",
        "    rules = []\n",
        "    itemsets = list(frequent_itemsets.keys())\n",
        "    support_lookup = frequent_itemsets\n",
        "\n",
        "    for itemset in itemsets:\n",
        "        if len(itemset) < 2:\n",
        "            continue  # Can't split 1-itemset into rule\n",
        "\n",
        "        # All possible antecedents (A) and consequents (B)\n",
        "        for i in range(1, len(itemset)):\n",
        "            antecedents = combinations(itemset, i)\n",
        "            for A in antecedents:\n",
        "                A = tuple(sorted(A))\n",
        "                B = tuple(sorted(set(itemset) - set(A)))\n",
        "\n",
        "                support_A = support_lookup.get(A, 0)\n",
        "                support_AB = support_lookup.get(itemset, 0)\n",
        "                support_B = support_lookup.get(B, 0)\n",
        "\n",
        "                if support_A == 0 or support_B == 0:\n",
        "                    continue\n",
        "\n",
        "                confidence = support_AB / support_A\n",
        "                lift = confidence / support_B\n",
        "\n",
        "                if confidence >= min_confidence and lift >= min_lift:\n",
        "                    rules.append({\n",
        "                        'antecedent': A,\n",
        "                        'consequent': B,\n",
        "                        'support': round(support_AB, 2),\n",
        "                        'confidence': round(confidence, 2),\n",
        "                        'lift': round(lift, 2)\n",
        "                    })\n",
        "\n",
        "    return rules"
      ],
      "metadata": {
        "id": "BMh2dVqkuXaM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Example Usage"
      ],
      "metadata": {
        "id": "RKU1seCRua1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rules = generate_association_rules(frequent_itemsets, min_confidence=0.6, min_lift=1.0)\n",
        "\n",
        "print(\"Association Rules:\")\n",
        "for r in rules:\n",
        "    A = ', '.join(r['antecedent'])\n",
        "    B = ', '.join(r['consequent'])\n",
        "    print(f\"{A} → {B}  (support={r['support']}, confidence={r['confidence']}, lift={r['lift']})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJa3wwSKubrK",
        "outputId": "f77f1c91-d15e-427f-8e26-3c878e694b80"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Association Rules:\n",
            "jam → bread  (support=0.5, confidence=1.0, lift=1.0)\n",
            "bread → milk  (support=0.67, confidence=0.67, lift=1.0)\n",
            "milk → bread  (support=0.67, confidence=1.0, lift=1.0)\n",
            "butter → bread  (support=0.5, confidence=1.0, lift=1.0)\n"
          ]
        }
      ]
    }
  ]
}